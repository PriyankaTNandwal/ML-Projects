{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Titanic - Machine Learning from Disaster\n",
    "This notebook provides end to end steps in solving the Titanic Problem"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10deb7f3a1cb225e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:06.242443900Z",
     "start_time": "2024-06-17T14:03:06.130443400Z"
    }
   },
   "id": "eb02ecd1bf156bae",
   "execution_count": 155
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reading the data from csv files."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ba68b795f366de"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 11)\n",
      "Number of Train Samples: 891\n",
      "Number of Features:      11\n",
      "Features:      ['PassengerId' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare'\n",
      " 'Cabin' 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train_labels = train[\"Survived\"]\n",
    "train_data = train.drop([\"Survived\"], axis = 1)\n",
    "\n",
    "NO_SAMPLES = train_data.shape[0]\n",
    "NO_FEATURES = train_data.shape[1]\n",
    "FEATURES = train_data.columns.to_numpy()\n",
    "\n",
    "TotalData = pd.concat([train_data, test], axis=0)\n",
    "\n",
    "print(TotalData.shape)\n",
    "\n",
    "print(f\"{'Number of Train Samples:'.ljust(25)}{NO_SAMPLES}\\n{'Number of Features:'.ljust(25)}{NO_FEATURES}\")\n",
    "print(f\"{'Features:'.ljust(15)}{FEATURES}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:06.341443700Z",
     "start_time": "2024-06-17T14:03:06.248443200Z"
    }
   },
   "id": "b7b44293e0086ac1",
   "execution_count": 156
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below are the utility functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d81beed3f4576cff"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    891\n",
      "Pclass           3\n",
      "Name           891\n",
      "Sex              2\n",
      "Age             88\n",
      "SibSp            7\n",
      "Parch            7\n",
      "Ticket         681\n",
      "Fare           248\n",
      "Cabin          147\n",
      "Embarked         3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_unique_count(df: pd.DataFrame):\n",
    "    print(df.nunique(axis=0))\n",
    "\n",
    "def check_missing_count(df: pd.DataFrame) -> dict:\n",
    "    return {column: df[column].isna().sum() for column in df.columns if df[column].isna().sum() > 0}\n",
    "\n",
    "check_unique_count(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:06.343442200Z",
     "start_time": "2024-06-17T14:03:06.284443500Z"
    }
   },
   "id": "be5b83d4ba11d98",
   "execution_count": 157
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Processing\n",
    "\n",
    "Following features are handled as follows:-\n",
    "\n",
    "FEATURE                         ACTION\n",
    "\n",
    "PassengerId                     DROP\n",
    "Pclass                          Ordinal Data , No Action\n",
    "Name                            Fetch Title\n",
    "Sex                             Nominal Data, 1 Hot Encode\n",
    "Age                             Bin Age into ['Child', 'Young Adult', 'Middle Aged', 'Senior'] [0, 18, 35, 50, 100]\n",
    "SibSp & Parch                   Add them to create a feature # Relatives\n",
    "Ticket                          Based on regex, split in groups and 1 hot encode\n",
    "Fare                            Normalization\n",
    "Cabin                           -\n",
    "Embarked                        Nominal Data, 1 Hot Encode\n",
    "\n",
    "STEPS:-\n",
    "\n",
    "1) Drop any feature which has more than 50% missing value\n",
    "2) Process all features as described above\n",
    "3) Impute Missing Values with KNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "601c91e3787581f4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Missing Count : \n",
      "{'Age': 177, 'Cabin': 687, 'Embarked': 2}\n",
      "\n",
      "Test Data Missing Count : \n",
      "{'Age': 86, 'Fare': 1, 'Cabin': 327}\n",
      "\n",
      "Training Features with missing value > 50%: \n",
      "['Cabin']\n"
     ]
    }
   ],
   "source": [
    "train_missing_count = check_missing_count(train_data)\n",
    "test_missing_count = check_missing_count(test)\n",
    "\n",
    "features_to_drop = list(dict(filter(lambda x: (x[1] > int(NO_SAMPLES/2)), train_missing_count.items())).keys())\n",
    "\n",
    "print(f\"Train Data Missing Count : \\n{check_missing_count(train_data)}\\n\")\n",
    "print(f\"Test Data Missing Count : \\n{check_missing_count(test)}\\n\")\n",
    "print(f\"Training Features with missing value > 50%: \\n{features_to_drop}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:06.360444300Z",
     "start_time": "2024-06-17T14:03:06.299443100Z"
    }
   },
   "id": "440218991dc6ec32",
   "execution_count": 158
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utility function for pre-processing features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "680ee2b35dd8f2b1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# One Hot Encode\n",
    "# pd.get_dummies(original_dataframe, columns=feature_to_encode, dtype=int, prefix=\"\", prefix_sep=\"\")\n",
    "def encode_and_bind(original_dataframe: pd.DataFrame, feature_to_encode: list) -> pd.DataFrame:\n",
    "    dummies = [original_dataframe]\n",
    "    for feature in feature_to_encode:\n",
    "        dummy = pd.get_dummies(original_dataframe[feature], prefix=feature, dtype=int)\n",
    "        dummies.append(dummy)\n",
    "    \n",
    "    titanic_dummies = pd.concat(dummies, axis=1)\n",
    "    encoded_df = titanic_dummies.drop(columns=feature_to_encode)\n",
    "    \n",
    "    return encoded_df\n",
    "\n",
    "# Bin Age Column\n",
    "def bin_age(df: pd.DataFrame, bins: list, labels: list[str], column: str, new_column: str) -> pd.DataFrame:\n",
    "    df[new_column] = pd.cut(df[column], bins=bins, labels=labels, right=False)\n",
    "    df.drop(columns=[column], inplace=True)\n",
    "    return df\n",
    "\n",
    "# normalize the titles\n",
    "normalized_titles = {\n",
    "    \"Capt\":       \"Officer\",\n",
    "    \"Col\":        \"Officer\",\n",
    "    \"Major\":      \"Officer\",\n",
    "    \"Jonkheer\":   \"Royalty\",\n",
    "    \"Don\":        \"Royalty\",\n",
    "    \"Sir\" :       \"Royalty\",\n",
    "    \"Dr\":         \"Officer\",\n",
    "    \"Rev\":        \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Dona\":       \"Royalty\",\n",
    "    \"Mme\":        \"Mrs\",\n",
    "    \"Mlle\":       \"Miss\",\n",
    "    \"Ms\":         \"Mrs\",\n",
    "    \"Mr\" :        \"Mr\",\n",
    "    \"Mrs\" :       \"Mrs\",\n",
    "    \"Miss\" :      \"Miss\",\n",
    "    \"Master\" :    \"Master\",\n",
    "    \"Lady\" :      \"Royalty\"\n",
    "}\n",
    "\n",
    "# Process all features together\n",
    "def pre_process_features(df: pd.DataFrame, columns_to_drop: list[str], one_hot_encode: list[str]=None) -> pd.DataFrame:\n",
    "    df = df.drop(columns = columns_to_drop, errors='ignore')\n",
    "    df.Cabin = df.Cabin.fillna('U')\n",
    "    df.Cabin = df.Cabin.map(lambda x: x[0])\n",
    "    df['Title'] = df.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())\n",
    "    df.Title = df.Title.map(normalized_titles)\n",
    "    df = df.drop(columns = [\"Name\"], errors='ignore')\n",
    "    df['Fare'] =  df['Fare'].fillna(df['Fare'].mean())\n",
    "    scaler = StandardScaler()    \n",
    "    df['Fare'] = scaler.fit_transform(df[['Fare']])\n",
    "    df['relatives'] = df['SibSp'] + df['Parch']\n",
    "    df[\"Ticket\"] = df[\"Ticket\"].str.lower().replace(regex={\n",
    "    r'^w.*': 0,\n",
    "    r'^s.*$':1,\n",
    "    r'^p.*$':2,\n",
    "    r'^l.*$':3,\n",
    "    r'^f.*$':4,\n",
    "    r'^c.*$':5,\n",
    "    r'^a.*$':6,\n",
    "    r'^\\d.*$':7,})\n",
    "    df.drop(columns = ['SibSp', 'Parch'], inplace=True)\n",
    "    #df['Sex'].replace({'male': 1, 'female': 0}, inplace=True)\n",
    "    #df['Embarked'].replace({'S': 0, 'C': 1, 'Q':2}, inplace=True)\n",
    "    binned_age_df = bin_age(df, AGE_BINS, LABELS, 'Age', \"AgeBin\")\n",
    "    nominal_features = ['Title', \"Cabin\"]\n",
    "    one_hot_encode.extend(nominal_features) if one_hot_encode  else nominal_features\n",
    "    encoded_df = encode_and_bind(binned_age_df, one_hot_encode) if one_hot_encode else binned_age_df\n",
    "    return encoded_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:06.419473Z",
     "start_time": "2024-06-17T14:03:06.322445800Z"
    }
   },
   "id": "60601eb0f21deb8a",
   "execution_count": 159
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DF_TO_ONE_HOT_ENCODE = [\"Embarked\", \"AgeBin\", \"Sex\", \"Ticket\"] # one-hot encoding these features producing better result.\n",
    "AGE_BINS = [0, 18, 35, 50, 100]\n",
    "#LABELS = ['Child', 'Young Adult', 'Middle Aged', 'Senior']\n",
    "LABELS = [0,1,2,3]\n",
    "COLUMNS_TO_DROP = ['PassengerId']\n",
    "processed_data = pre_process_features(TotalData, COLUMNS_TO_DROP, DF_TO_ONE_HOT_ENCODE)\n",
    "#processed_testing_data = pre_process_features(test, COLUMNS_TO_DROP, DF_TO_ONE_HOT_ENCODE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:06.439468200Z",
     "start_time": "2024-06-17T14:03:06.331443100Z"
    }
   },
   "id": "82382a4663fd1c9d",
   "execution_count": 160
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       408, 409, 410, 411, 412, 413, 414, 415, 416, 417],\n      dtype='int64', length=1309)"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#processed_data.head()\n",
    "processed_data.index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:06.441445700Z",
     "start_time": "2024-06-17T14:03:06.377443400Z"
    }
   },
   "id": "3845e287e42aa174",
   "execution_count": 161
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass      Fare  relatives  Embarked_C  Embarked_Q  Embarked_S  AgeBin_0  \\\n",
      "0     3.0 -0.503595        1.0         0.0         0.0         1.0       0.0   \n",
      "1     1.0  0.734503        1.0         1.0         0.0         0.0       0.0   \n",
      "2     3.0 -0.490544        0.0         0.0         0.0         1.0       0.0   \n",
      "3     1.0  0.382925        1.0         0.0         0.0         1.0       0.0   \n",
      "4     3.0 -0.488127        0.0         0.0         0.0         1.0       0.0   \n",
      "\n",
      "   AgeBin_1  AgeBin_2  AgeBin_3  ...  Title_Royalty  Cabin_A  Cabin_B  \\\n",
      "0       1.0       0.0       0.0  ...            0.0      0.0      0.0   \n",
      "1       0.0       1.0       0.0  ...            0.0      0.0      0.0   \n",
      "2       1.0       0.0       0.0  ...            0.0      0.0      0.0   \n",
      "3       0.0       1.0       0.0  ...            0.0      0.0      0.0   \n",
      "4       0.0       1.0       0.0  ...            0.0      0.0      0.0   \n",
      "\n",
      "   Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_T  Cabin_U  \n",
      "0      0.0      0.0      0.0      0.0      0.0      0.0      1.0  \n",
      "1      1.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "2      0.0      0.0      0.0      0.0      0.0      0.0      1.0  \n",
      "3      1.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
      "4      0.0      0.0      0.0      0.0      0.0      0.0      1.0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer()\n",
    "\n",
    "data = imputer.fit_transform(processed_data)\n",
    "data = pd.DataFrame(data, columns=processed_data.columns)\n",
    "\n",
    "print(data.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:06.500466900Z",
     "start_time": "2024-06-17T14:03:06.442444200Z"
    }
   },
   "id": "e603136c00844429",
   "execution_count": 162
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "af10fab9a60bbee5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TRAINING DATA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "640b2585e0b06617"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = plt.figure(figsize=(19, 15))\n",
    "plt.matshow(processed_train_data.corr(), fignum=f.number)\n",
    "plt.xticks(range(processed_train_data.select_dtypes(['number']).shape[1]), processed_train_data.select_dtypes(['number']).columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(processed_train_data.select_dtypes(['number']).shape[1]), processed_train_data.select_dtypes(['number']).columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix', fontsize=16);\n",
    "'''\n",
    "\n",
    "train_data = data[:NO_SAMPLES]\n",
    "test_data = data[NO_SAMPLES:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:06.519444700Z",
     "start_time": "2024-06-17T14:03:06.489443300Z"
    }
   },
   "id": "a76ec489525d03ed",
   "execution_count": 163
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_submission_csv(predictions, prefix):\n",
    "    submission_df = pd.DataFrame(predictions, index=test[\"PassengerId\"], columns=[\"Survived\"])\n",
    "    submission_df.to_csv(f\"gender_submission_{prefix}.csv\")\n",
    "    print(\"File saved successfully\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:06.551442500Z",
     "start_time": "2024-06-17T14:03:06.509444700Z"
    }
   },
   "id": "ede2fd32c97ee8ff",
   "execution_count": 164
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "classifier_results = pd.DataFrame(columns=[\"DecisionTree\", \"RandomForest\", \"KNN\", \"XGB\", \"SVM\", \"Voting\"], index=[\"accuracy\", \"CV_mean\", \"CV_std\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:06.555443100Z",
     "start_time": "2024-06-17T14:03:06.522442600Z"
    }
   },
   "id": "1879f31a9ed1abb3",
   "execution_count": 165
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Tree Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc563d6236f8f573"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT CV Mean and Std81.37203495630463, 0.03044648971540275\n",
      "Decision Tree Training Score: 85.40965207631874\n",
      "File saved successfully\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=1, min_samples_split=4, max_depth=5)\n",
    "cv_results = cross_val_score(dt, train_data, train_labels, cv=kfold, scoring='accuracy')\n",
    "dt.fit(train_data, train_labels)\n",
    "score = dt.score(train_data, train_labels)*100\n",
    "\n",
    "print(f\"DT CV Mean and Std{cv_results.mean() * 100}, {cv_results.std()}\")\n",
    "print(f'Decision Tree Training Score: {score}')\n",
    "classifier_results.DecisionTree = [score, cv_results.mean(), cv_results.std()]\n",
    "\n",
    "predictions_dt = dt.predict(test_data)\n",
    "create_submission_csv(predictions_dt, \"dt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:06.661441300Z",
     "start_time": "2024-06-17T14:03:06.560443600Z"
    }
   },
   "id": "4671bfcf8e7eae7e",
   "execution_count": 166
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f940c58676754751"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CV Mean and Std:  80.92384519350813, 0.03231408930355503\n",
      "Random Forest Training Score: 95.95959595959596\n",
      "File saved successfully\n"
     ]
    }
   ],
   "source": [
    "rfc=RandomForestClassifier(random_state=4)\n",
    "cv_results = cross_val_score(rfc, train_data, train_labels, cv=kfold, scoring='accuracy')\n",
    "rfc.fit(train_data, train_labels)\n",
    "score = rfc.score(train_data, train_labels)*100\n",
    "\n",
    "print(f\"Random Forest CV Mean and Std:  {cv_results.mean() * 100}, {cv_results.std()}\")\n",
    "print(f'Random Forest Training Score: {score}')\n",
    "classifier_results.RandomForest = [score, cv_results.mean(), cv_results.std()]\n",
    "\n",
    "predictions_rf = rfc.predict(test_data)\n",
    "create_submission_csv(predictions_rf, \"rf\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:08.480443400Z",
     "start_time": "2024-06-17T14:03:06.650444200Z"
    }
   },
   "id": "aac462dd8968d85c",
   "execution_count": 167
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN  Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b71e0ef5554c2ec"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CV Mean and Std:  80.80898876404495, 0.022068285298320754\n",
      "KNN Training Score: 85.85858585858585\n",
      "File saved successfully\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "cv_results = cross_val_score(knn, train_data, train_labels, cv=kfold, scoring='accuracy')\n",
    "knn.fit(train_data, train_labels)\n",
    "\n",
    "score = knn.score(train_data, train_labels)*100\n",
    "\n",
    "print(f\"KNN CV Mean and Std:  {cv_results.mean() * 100}, {cv_results.std()}\")\n",
    "print(f'KNN Training Score: {score}')\n",
    "classifier_results.KNN = [score, cv_results.mean(), cv_results.std()]\n",
    "\n",
    "predictions_knn = knn.predict(test_data)\n",
    "create_submission_csv(predictions_knn, \"knn\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:08.732443200Z",
     "start_time": "2024-06-17T14:03:08.478443800Z"
    }
   },
   "id": "bafd9a21f66d9bdc",
   "execution_count": 168
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XGB Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95b31944413a70bd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB CV Mean and Std:  81.37328339575531, 0.02818709771120117\n",
      "XGB Training Score: 94.38832772166106\n",
      "File saved successfully\n"
     ]
    }
   ],
   "source": [
    "seed = 10\n",
    "test_size = 0.33\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "cv_results = cross_val_score(xgb, train_data, train_labels, cv=kfold, scoring='accuracy')\n",
    "xgb.fit(train_data, train_labels)\n",
    "score = xgb.score(train_data, train_labels)*100\n",
    "\n",
    "print(f\"XGB CV Mean and Std:  {cv_results.mean() * 100}, {cv_results.std()}\")\n",
    "print(f'XGB Training Score: {score}')\n",
    "classifier_results.XGB = [score, cv_results.mean(), cv_results.std()]\n",
    "\n",
    "predictions_xgb = xgb.predict(test_data)\n",
    "create_submission_csv(predictions_xgb, \"xgb\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:09.435443400Z",
     "start_time": "2024-06-17T14:03:08.732443200Z"
    }
   },
   "id": "a312b7b27e39f5e",
   "execution_count": 169
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ded19db758111d0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM CV Mean and Std:  83.50062421972535, 0.019571071366547232\n",
      "SVM Training Score: 83.72615039281706\n",
      "File saved successfully\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=0.5, kernel='rbf', tol=0.00001, degree=2)\n",
    "cv_results = cross_val_score(svm, train_data, train_labels, cv=kfold, scoring='accuracy')\n",
    "svm.fit(train_data, train_labels)\n",
    "score = svm.score(train_data, train_labels)*100\n",
    "\n",
    "print(f\"SVM CV Mean and Std:  {cv_results.mean() * 100}, {cv_results.std()}\")\n",
    "print(f'SVM Training Score: {score}')\n",
    "classifier_results.SVM = [score, cv_results.mean(), cv_results.std()]\n",
    "\n",
    "predictions_svm = svm.predict(test_data)\n",
    "create_submission_csv(predictions_svm, \"svc\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:09.812441700Z",
     "start_time": "2024-06-17T14:03:09.432445900Z"
    }
   },
   "id": "127a29cc89c7b51e",
   "execution_count": 170
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Voting Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbef9d1d10baf90a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_classifier CV Mean and Std:  81.93383270911362, 0.020631265554427555\n",
      "voting_classifier Training Score: 91.02132435465768\n",
      "File saved successfully\n"
     ]
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('svm', svm), \n",
    "    ('dt', dt),\n",
    "    ('rfc', rfc),\n",
    "    ('rf', rfc),\n",
    "    ('knn', knn)], voting='hard')\n",
    "\n",
    "cv_results = cross_val_score(voting_classifier, train_data, train_labels, cv=kfold, scoring='accuracy')\n",
    "voting_classifier.fit(train_data, train_labels)\n",
    "\n",
    "score = voting_classifier.score(train_data, train_labels)*100\n",
    "\n",
    "print(f\"voting_classifier CV Mean and Std:  {cv_results.mean() * 100}, {cv_results.std()}\")\n",
    "print(f'voting_classifier Training Score: {score}')\n",
    "classifier_results.Voting = [score, cv_results.mean(), cv_results.std()]\n",
    "\n",
    "predictions_voting = voting_classifier.predict(test_data)\n",
    "create_submission_csv(predictions_voting, \"voting\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:14.091443Z",
     "start_time": "2024-06-17T14:03:09.814444Z"
    }
   },
   "id": "fdf98a593d6dea38",
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          DecisionTree  RandomForest        KNN        XGB        SVM  \\\naccuracy     85.409652     95.959596  85.858586  94.388328  83.726150   \nCV_mean       0.813720      0.809238   0.808090   0.813733   0.835006   \nCV_std        0.030446      0.032314   0.022068   0.028187   0.019571   \n\n             Voting  \naccuracy  91.021324  \nCV_mean    0.819338  \nCV_std     0.020631  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DecisionTree</th>\n      <th>RandomForest</th>\n      <th>KNN</th>\n      <th>XGB</th>\n      <th>SVM</th>\n      <th>Voting</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy</th>\n      <td>85.409652</td>\n      <td>95.959596</td>\n      <td>85.858586</td>\n      <td>94.388328</td>\n      <td>83.726150</td>\n      <td>91.021324</td>\n    </tr>\n    <tr>\n      <th>CV_mean</th>\n      <td>0.813720</td>\n      <td>0.809238</td>\n      <td>0.808090</td>\n      <td>0.813733</td>\n      <td>0.835006</td>\n      <td>0.819338</td>\n    </tr>\n    <tr>\n      <th>CV_std</th>\n      <td>0.030446</td>\n      <td>0.032314</td>\n      <td>0.022068</td>\n      <td>0.028187</td>\n      <td>0.019571</td>\n      <td>0.020631</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:14.131440900Z",
     "start_time": "2024-06-17T14:03:14.094443300Z"
    }
   },
   "id": "d5cfcabd7f45f7e9",
   "execution_count": 172
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "classifier_results.loc[\"Test_accuracies\", 'DecisionTree'] = .76555\n",
    "classifier_results.loc[\"Test_accuracies\", 'RandomForest'] = .76794\n",
    "classifier_results.loc[\"Test_accuracies\", 'KNN'] = .76794\n",
    "classifier_results.loc[\"Test_accuracies\", 'XGB'] = .77272\n",
    "classifier_results.loc[\"Test_accuracies\", 'SVM'] = .77751\n",
    "classifier_results.loc[\"Test_accuracies\", 'Voting'] = .77272"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:14.133441200Z",
     "start_time": "2024-06-17T14:03:14.110442900Z"
    }
   },
   "id": "4a748dfb70659942",
   "execution_count": 173
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                 DecisionTree  RandomForest        KNN        XGB        SVM  \\\naccuracy            85.409652     95.959596  85.858586  94.388328  83.726150   \nCV_mean              0.813720      0.809238   0.808090   0.813733   0.835006   \nCV_std               0.030446      0.032314   0.022068   0.028187   0.019571   \nTest_accuracies      0.765550      0.767940   0.767940   0.772720   0.777510   \n\n                    Voting  \naccuracy         91.021324  \nCV_mean           0.819338  \nCV_std            0.020631  \nTest_accuracies   0.772720  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DecisionTree</th>\n      <th>RandomForest</th>\n      <th>KNN</th>\n      <th>XGB</th>\n      <th>SVM</th>\n      <th>Voting</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>accuracy</th>\n      <td>85.409652</td>\n      <td>95.959596</td>\n      <td>85.858586</td>\n      <td>94.388328</td>\n      <td>83.726150</td>\n      <td>91.021324</td>\n    </tr>\n    <tr>\n      <th>CV_mean</th>\n      <td>0.813720</td>\n      <td>0.809238</td>\n      <td>0.808090</td>\n      <td>0.813733</td>\n      <td>0.835006</td>\n      <td>0.819338</td>\n    </tr>\n    <tr>\n      <th>CV_std</th>\n      <td>0.030446</td>\n      <td>0.032314</td>\n      <td>0.022068</td>\n      <td>0.028187</td>\n      <td>0.019571</td>\n      <td>0.020631</td>\n    </tr>\n    <tr>\n      <th>Test_accuracies</th>\n      <td>0.765550</td>\n      <td>0.767940</td>\n      <td>0.767940</td>\n      <td>0.772720</td>\n      <td>0.777510</td>\n      <td>0.772720</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T14:03:14.159441Z",
     "start_time": "2024-06-17T14:03:14.125446200Z"
    }
   },
   "id": "f7be45a1c98135a0",
   "execution_count": 174
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
